import sys
import os

# Add the project root to the Python path to allow direct script execution
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

import pytest
from sqlalchemy.orm import Session
import uuid

# Assuming your project structure allows these imports
from db import models, crud
from services.text_analysis import process_text_analysis
from db.database import SessionLocal, engine, Base, DATABASE_URL # Or however you get your test session

# Create tables if they don't exist
Base.metadata.create_all(bind=engine)

# Placeholder for test database setup/teardown if needed
# You might use pytest fixtures for this (e.g., setting up a test DB)

TEST_TEXT_CONTENT = """Sarah walked through the garden, brushing against wild roses. "I can't believe this place is abandoned," she whispered, wonder in her voice.
"People fear Mrs. Wilson's ghost," Tom replied, emerging from behind a tree. His deep voice carried amusement.
Sarah rolled her eyes. "Don't be ridiculous," she said firmly. "There's no such thing as ghosts."
Their dog Max froze, ears perked up, staring at the mansion window.
"Tom," Sarah clutched his arm, voice trembling. "I saw something move up there!"
"Just the curtains," Tom assured her, uncertainty creeping into his tone.
Neither noticed the elderly woman watching them from the window as Max continued to stare in her direction."""

@pytest.mark.integration  # Mark as integration test
def test_full_text_analysis_pipeline():
    """
    Tests the full text analysis pipeline from text input to DB records,
    using the real Anthropic API. Requires ANTHROPIC_API_KEY environment variable.
    """
    print(f"DATABASE_URL used in test: {DATABASE_URL}")
    print(f"Engine URL used in test: {engine.url}")
    # Create a regular database session
    db = SessionLocal()
    try:
        # 1. Setup: Create initial Text record
        db_text = crud.create_text(db, content=TEST_TEXT_CONTENT, title="Integration Test Text")
        assert db_text is not None
        text_id = str(db_text.id)  # Use the autogenerated ID
        text_uuid = db_text.id     # Keep the UUID object for queries
        assert db_text.analyzed is False
        
        # Force commit to ensure the record is saved
        db.commit()
        
        print(f"Created text with ID: {text_id}")

        # 2. Execute: Run the processing function
        # This will call the real Anthropic API
        updated_db_text = process_text_analysis(db=db, text_id=text_id, content=TEST_TEXT_CONTENT)

        # 3. Verify: Check results in the database
        db.refresh(updated_db_text)

        # Verify Text record update
        assert updated_db_text.analyzed is True

        # Verify Characters - Use the UUID object directly instead of string
        characters = db.query(models.Character).filter(models.Character.text_id == text_uuid).all()
        # --- TODO: Add specific assertions based on expected characters ---
        # Example: Check if Sarah, Tom, and Narrator (or similar) were created
        # Example: Check if fields like is_narrator, speaking, persona_description have values
        assert len(characters) > 0 # Basic check, refine later
        print(f"Found characters: {[c.name for c in characters]}")
        # for char in characters:
        #     assert char.persona_description is not None
        #     assert char.intro_text is not None
        #     assert isinstance(char.is_narrator, bool)
        #     assert isinstance(char.speaking, bool)

        # Verify Segments - Use the UUID object directly instead of string
        segments = db.query(models.TextSegment).filter(models.TextSegment.text_id == text_uuid).order_by(models.TextSegment.sequence).all()
        # --- TODO: Add specific assertions based on expected segments ---
        # Example: Check the number of segments
        # Example: Check if fields like description, speed, trailing_silence have values
        # Example: Check if segment text matches parts of the input
        assert len(segments) > 0 # Basic check, refine later
        print(f"Found {len(segments)} segments.")
        # for i, seg in enumerate(segments):
        #     assert seg.sequence == i + 1 # Check sequence order
        #     assert seg.character_id is not None
        #     assert seg.text is not None
        #     assert seg.description is not None
        #     assert seg.speed is not None
        #     assert seg.trailing_silence is not None

        # Explicitly commit any remaining changes to keep data in database
        db.commit()
        
        print(f"Test completed. Data for text ID {text_id} is preserved in database.")

    finally:
        # Always close the session, but don't rollback
        db.close() 