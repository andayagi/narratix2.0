import sys
import os
import datetime

# Add the project root to the Python path to allow direct script execution
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

import pytest
from sqlalchemy.orm import Session
import uuid

# Assuming your project structure allows these imports
from db import models, crud
from services.text_analysis import process_text_analysis
from db.database import SessionLocal, engine, Base, DATABASE_URL # Or however you get your test session
from utils.config import setup_run_logging

# Create tables if they don't exist
Base.metadata.create_all(bind=engine)

# Placeholder for test database setup/teardown if needed
# You might use pytest fixtures for this (e.g., setting up a test DB)

# Load test content from fixture file using absolute path
fixture_file = '/Users/anatburg/Narratix2.0/tests/fixtures/text_analysis_example'
with open(fixture_file, 'r', encoding='utf-8') as f:
    BASE_TEST_TEXT_CONTENT = f.read()

@pytest.mark.integration  # Mark as integration test
def test_full_text_analysis_pipeline():
    """
    Tests the full text analysis pipeline from text input to DB records,
    using the real Anthropic API. Requires ANTHROPIC_API_KEY environment variable.
    """
    # Setup a single logging session for all operations in this test
    session_id = setup_run_logging("test_session")
    
    print(f"DATABASE_URL used in test: {DATABASE_URL}")
    print(f"Engine URL used in test: {engine.url}")
    
    # Create a regular database session
    db = SessionLocal()
    try:
        # Check if text with this content already exists
        existing_text = crud.get_text_by_content(db, BASE_TEST_TEXT_CONTENT)
        
        if existing_text:
            print(f"Found existing text with ID: {existing_text.id}")
            text_id = str(existing_text.id)
            text_uuid = existing_text.id
            
            print(f"Will update existing text record and replace analysis")
            
            # Store the original last_updated timestamp
            original_last_updated = existing_text.last_updated
            print(f"Original last_updated: {original_last_updated}")
            
            # Set analyzed to False to ensure reanalysis if process_text_analysis relies on it
            # or if we want to simulate a full re-processing flow.
            existing_text.analyzed = False # Ensure it gets re-analyzed by process_text_analysis
            db.commit()
            db.refresh(existing_text)
            
            db_text = existing_text
        else:
            # 1. Setup: Create initial Text record
            db_text = crud.create_text(db, content=BASE_TEST_TEXT_CONTENT, title="Integration Test Text")
            assert db_text is not None
            text_id = str(db_text.id)  # Use the autogenerated ID
            text_uuid = db_text.id     # Keep the UUID object for queries
            assert db_text.analyzed is False
            original_last_updated = None  # No original timestamp for new records
            
            print(f"Created new text with ID: {text_id}")
            
            # Force commit to ensure the record is saved
            db.commit()
        
        # 2. Execute: Run the processing function
        # This will call the real Anthropic API
        updated_db_text = process_text_analysis(db=db, text_id=int(text_id), content=BASE_TEST_TEXT_CONTENT)

        # 3. Verify: Check results in the database
        db.refresh(updated_db_text)

        # Verify Text record update
        assert updated_db_text.analyzed is True
        
        # If this was an update, verify the last_updated timestamp was changed
        if original_last_updated:
            print(f"New last_updated: {updated_db_text.last_updated}")
            assert updated_db_text.last_updated > original_last_updated, "last_updated timestamp wasn't updated"

        # Verify Characters - Use the UUID object directly instead of string
        characters = db.query(models.Character).filter(models.Character.text_id == text_uuid).all()
        assert len(characters) > 0 # Basic check, refine later
        print(f"Found characters: {[c.name for c in characters]}")

        # Verify Segments - Use the UUID object directly instead of string
        segments = db.query(models.TextSegment).filter(models.TextSegment.text_id == text_uuid).order_by(models.TextSegment.sequence).all()
        assert len(segments) > 0 # Basic check, refine later
        print(f"Found {len(segments)} segments.")

        # Explicitly commit any remaining changes to keep data in database
        db.commit()
        
        print(f"Test completed. Data for text ID {text_id} is preserved in database.")

    finally:
        # Always close the session, but don't rollback
        db.close() 