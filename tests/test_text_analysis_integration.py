import pytest
from sqlalchemy.orm import Session
import uuid

# Assuming your project structure allows these imports
from db import models, crud
from services.text_analysis import process_text_analysis
from db.database import SessionLocal # Or however you get your test session

# Placeholder for test database setup/teardown if needed
# You might use pytest fixtures for this (e.g., setting up a test DB)

TEST_TEXT_CONTENT = """Sarah walked through the garden, brushing against wild roses. "I can't believe this place is abandoned," she whispered, wonder in her voice.
"People fear Mrs. Wilson's ghost," Tom replied, emerging from behind a tree. His deep voice carried amusement.
Sarah rolled her eyes. "Don't be ridiculous," she said firmly. "There's no such thing as ghosts."
Their dog Max froze, ears perked up, staring at the mansion window.
"Tom," Sarah clutched his arm, voice trembling. "I saw something move up there!"
"Just the curtains," Tom assured her, uncertainty creeping into his tone.
Neither noticed the elderly woman watching them from the window as Max continued to stare in her direction."""

@pytest.mark.integration  # Mark as integration test
def test_full_text_analysis_pipeline():
    """
    Tests the full text analysis pipeline from text input to DB records,
    using the real Anthropic API.
    Requires ANTHROPIC_API_KEY environment variable.
    """
    # Create a regular database session
    db = SessionLocal()
    try:
        text_id = str(uuid.uuid4())
        user_id = str(uuid.uuid4()) # Assuming a user ID is needed for text creation

        # 1. Setup: Create initial Text record
        db_text = crud.create_text(db, content=TEST_TEXT_CONTENT, title="Integration Test Text")
        assert db_text is not None
        text_id = str(db_text.id)  # Use the autogenerated ID
        assert db_text.analyzed is False

        # 2. Execute: Run the processing function
        # This will call the real Anthropic API
        updated_db_text = process_text_analysis(db=db, text_id=text_id, content=TEST_TEXT_CONTENT)

        # 3. Verify: Check results in the database
        db.refresh(updated_db_text)

        # Verify Text record update
        assert updated_db_text.analyzed is True

        # Verify Characters
        characters = db.query(models.Character).filter(models.Character.text_id == text_id).all()
        # --- TODO: Add specific assertions based on expected characters ---
        # Example: Check if Sarah, Tom, and Narrator (or similar) were created
        # Example: Check if fields like is_narrator, speaking, persona_description have values
        assert len(characters) > 0 # Basic check, refine later
        print(f"Found characters: {[c.name for c in characters]}")
        # for char in characters:
        #     assert char.persona_description is not None
        #     assert char.intro_text is not None
        #     assert isinstance(char.is_narrator, bool)
        #     assert isinstance(char.speaking, bool)

        # Verify Segments
        segments = db.query(models.TextSegment).filter(models.TextSegment.text_id == text_id).order_by(models.TextSegment.sequence).all()
        # --- TODO: Add specific assertions based on expected segments ---
        # Example: Check the number of segments
        # Example: Check if fields like description, speed, trailing_silence have values
        # Example: Check if segment text matches parts of the input
        assert len(segments) > 0 # Basic check, refine later
        print(f"Found {len(segments)} segments.")
        # for i, seg in enumerate(segments):
        #     assert seg.sequence == i + 1 # Check sequence order
        #     assert seg.character_id is not None
        #     assert seg.text is not None
        #     assert seg.description is not None
        #     assert seg.speed is not None
        #     assert seg.trailing_silence is not None

        # --- Optional: Add more detailed checks based on expected API output ---
        # e.g., verify specific persona descriptions or segment acting notes.
        # This will require knowing the expected output from the LLM for the test text.

    finally:
        # Always close the session
        db.close() 